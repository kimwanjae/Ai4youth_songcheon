{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, you have learnt how to train a model and how to use it for predictions. While that is essential in any data science project, it is not sufficient to just train a model and using it for predictions. This is because even though the model has been trained, we did not evaluate its performance. \n",
    "\n",
    "The model has to be evaluated against data that was not used to train the model. This is because while the model may perform very well with data that it has trained with, it may not be useful if the model is not able to be used for data that it was not trained with. Thus, in this notebook, we will also learn how to ensure that this does not happen. Before we do so, we have to first understand why a model can perform poorly to unseen data even after training. This could be due to either underfitting or overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Underfitting vs Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underfitting means that the model is too simplified to be able to explain the data. For example, if you have data that has a non-linear relationship but you are using a linear model to train on, you may suffer from underfitting. This is because the linear model will not be able to explain the non-linear relationship or trend that is observed in the data. Thus, when you use an underfitted model to predict, it will perform poorly.\n",
    "\n",
    "On the other hand, overfitting means that the model is fitted so well that it has also learnt all the noise or outliers within the dataset. As such, it can perform very well when you test it against data that it has been trained with. However, because it is so well trained, it will not be able to generalise and thus, will not perform well when you are testing it against data that it was not trained with.\n",
    "\n",
    "Read this [article](https://medium.com/greyatom/what-is-underfitting-and-overfitting-in-machine-learning-and-how-to-deal-with-it-6803a989c76) and this [article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229) for more information about underfitting and overfitting and note down any interesting information in the cell below. While there may be some mathematical equations within the articles, it is ok if you are not able to understand the equations. It is more important to understand the underlying concepts. What is the difference between bias and variance? How do you prevent underfitting? How do you prevent overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the figures below. If the red line were to be your model and the blue points are the dataset, would the model be overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './resources/model1.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './resources/model2.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Balance between underfitting and overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that it is important to try and find a balance between underfitting and overfitting. This will allow the model to be accurate but still be able to generalise or perform well on data that it has not been trained in. This means that the model has to be somewhat complex but not too complex. As such, there are some ways that we can try to achieve the balance. We will try some of these methods for the different machine learning techniques that were explored earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an earlier workshop, we learnt how to apply the K-Nearest Neighbour (KNN) algorithm to classify data. As a recap, KNN classifies data points based on the majority of the other points that are closest to the point in question. However, in order to use the algorithm, there was a need to input the number of neighbours as a parameter. In the case of underfitting and overfitting, the number of neighbours do play an important role. This is because the number of neighbours determine how likely the model will overfit. The higher the number of neighbours, the less likely the model will overfit. If the number of neighbours is too high, it will be likely for the model to underfit. Thus, there should be some number in between the two extreme numbers that will allow the model to be relatively balanced. This number will differ for different datasets. We will now try to find this number for the Iris Flower dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to read in the Iris Flower dataset as a dataframe df from iris.data. Remember to check if the dataframe has column names and also perform the standard checks for the dataset (i.e check for erroneous data and outliers). You can refer to the picture (source: https://www.researchgate.net/figure/Trollius-ranunculoide-flower-with-measured-traits_fig6_272514310) below to understand the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/PetalSepal1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, perform the necessary steps that are required to prepare the data to be processed by a machine learning algroithm. First, extract the features as x_values and the target variable as y_values. In this case, the x_values will be \"sepal_length\", \"sepal_width\", \"petal_length\" and \"petal_width\" whereas the y_values will be the class. Additionally, remmeber to label encode the y_values. You can encode \"Setosa\" as 0, \"Versicolor\" as 1 and \"Virginica\" as 2. Refer to earlier notebooks if you require a reference for the necessary codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we are assurred that the data is ready to be processed by a machine learning technique, we can now focus on how to balance the overfitting and underfitting issue.\n",
    "\n",
    "If we want to determine this balance, we will need to be able to evaluate how well the model will perform or how accuracte the model will be if the model were to be applied to data that it has not been trained with. As we do not have future data, we will need to be able to use the current data to perform this evaluation. As such, the current dataset is usually split into 2 different groups. One group will contain all the training data which will be used to train the data. On the other hand, the other group will contain test data that will not be seen or used in the model training phase. The test data will serve as \"future\" data which will be used to evaluate the model.\n",
    "\n",
    "In order to split the data into 2 groups, we will use the train_test_split function from sklearn.model_selection. Try the code below to import the train_test_split function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the train_test_split function to split the data into the train group and the test group. The test group usually will contain 20% to 30% of the dataset. In this case, we can split the data based on 75% in the train group and 25% in the test group. Read this [article](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6) to understand how to use the train_test_split function. You can create variables called x_train, y_train, x_test and y_test to hold the training and testing data. Additionally, you can also add a random_state to ensure that the data is always split the same way everytime you run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data, we now have to standardise or normalise the data. It is always good practice to standardise or normalise any dataset that you use for machine learning. This will help scale the values for all the variables or features into similar ranges. Always remember to conduct the standardisation or normalisation after the data has been split. This is to ensure that the test dataset will always remain unseen by the model and not used in the normalisation or standardisation process of the training data.\n",
    "\n",
    "In this case, we will choose to use StandardScaler from sklearn.preprocessing to standardise the data. Remember to apply the .fit_transform method to the x_train data values but only the .transform method to the x_test data. Implement the standardisation process in the cell below. Create a variable called x_train_scale for the train data after standardisation and create another variable called x_test scale for the test data after standardisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardising the data, we can now implement a way to find the optimal number of neighbours for the KNN algorithm. To do so, we will train the KNN algorithm with differnt number of neighbours and also evaluate against the test data. By doing so, we will be able to obtain the accuracy of the KNN model for different number of neighbours. We can then find the number of neighbours that correspond to the highest accuracy. That number will be the optimal number of neighbours. Try the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the accuracy and number of neighbours for each KNN model\n",
    "accuracy = []\n",
    "num_neigh = []\n",
    "\n",
    "# Use ii to cycle through values 1 to 15. This will be the number of neighbours for the KNN classifier. \n",
    "for ii in range(1,16):\n",
    "    # Set number of neighbours to ii\n",
    "    KNN = KNeighborsClassifier(n_neighbors=ii)\n",
    "    # Training or fitting the model with the data\n",
    "    KNN.fit(x_train_scale,y_train)\n",
    "    # .score provides the accuracy of the model based on the testing data. Store the accuracy into the list.\n",
    "    accuracy.append(KNN.score(x_test_scale,y_test))\n",
    "    # Append the number of neighbours to a list\n",
    "    num_neigh.append(ii)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the accuracy values on the graph to help us determine the optimal number of neighbours. Try the code below! Remember to import matplotlib.pyplot as plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(num_neigh,accuracy)\n",
    "plt.xlabel('Number of neighbours')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, which will be the optimal number of neighbours to use? Explain your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible for a decision tree to underfit or overfit.\n",
    "\n",
    "For example, if the tree only has 1 decision point then it is likely for the tree to underfit. However, if the tree has multiple decision points, then it is possible for the tree to overfit. As such, the deeper the tree, the more likely it is for the tree to overfit. Based on your understanding of overfitting and underfitting, decide which trees (shown below) will be likely to overfit or underfit the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/dt1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = './resources/dt2.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, another way to control for overfitting or underfitting is based on the minimum number of samples that are at a decision point before a split is conducted. For example, if we have a decision point in the tree that is based on weather and there are 50 different points either consisting of sunny days or rainy days, it will be obvious that we should split the data at that decision point as there are quite a few samples or data points. However, if we only have 2 data points at that weather decision point, then it may not be necessary to split them based on weather as it may lead to overfitting. Thus, we can also use the number of samples at a decision point to control the fit.\n",
    "\n",
    "You can read this [article](https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3) to understand more on how to control for overfitting and underfitting in a decision tree. What are the other variables that we can use to control the fit in a decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to find the best set of parameters to allow the decision tree to have a good fit on the Iris Flower dataset. We can use the same splitted datasets from the earlier exercise above. Try the code below! The variable that we are using to control the fit in the tree is known as max_depth. This refers to the maximum depth of the tree. The deeper the tree, the more likely it is for the tree to overfit. Remember to import tree from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the accuracy and the best tested parameter for each decision tree\n",
    "accuracy = []\n",
    "depth = []\n",
    "\n",
    "# Use ii to cycle through values 1 to 9. This will be the max_depth value for the decision tree. \n",
    "for ii in range(1,10):\n",
    "    # Set max_depth to ii\n",
    "    dt = tree.DecisionTreeClassifier(max_depth=ii)\n",
    "    # Training or fitting the model with the data\n",
    "    dt.fit(x_train_scale,y_train)\n",
    "    # .score provides the accuracy of the model based on the testing data. Store the accuracy into the list.\n",
    "    accuracy.append(dt.score(x_test_scale,y_test))\n",
    "    # Append the max_depth values to a list\n",
    "    depth.append(ii)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you plot the accuracy values against the max_depth values in a graph? You can refer to the earlier graph for referrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, which will be the recommended max_depth value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you recall, the minimum number of samples at a decision point can also be used to prevent overfitting or underfitting. In the decision tree algorithm, this value is controlled by min_samples_split. Copy the code above and modify it to find the best min_samples_split value. You can use the range between 2 and 15. Plot the accuracy values for easy visualisation as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From your graph, which will be the best min_samples_split value? Would you choose the lowest value with the highest accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
