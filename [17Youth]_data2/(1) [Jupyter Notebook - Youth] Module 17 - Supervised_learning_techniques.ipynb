{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different types of machine learning techniques which can be used for various kinds of data science problems. You will learn some of the commonly used machine learning techniques in this workshop.\n",
    "\n",
    "Machine learning refers to the ability of the computer to learn patterns and relationships between data variables. They can do this through previous examples or learning from current datasets. After learning these patterns and relationships, you will be able to predict one variable given the knowledge of other variables. Read this [article](https://hackernoon.com/the-simplest-explanation-of-machine-learning-youll-ever-read-bebc0700047c) to find out more about machine learning. Write down any information that you find interesting in your worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Supervised Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you used the video sharing site Youtube before? Do you realise that it will recommend videos that it thinks you will like to watch? How do you think it can do that? \n",
    "\n",
    "It is able to do so through the usage of something known as supervised learning techniques. Everytime you like a video, the information will be stored in the system. It will also store the video history of what you watched and what other people who also liked the video watched.\n",
    "\n",
    "This information can be used to train a supervised learning technique which will predict which video you will want to watch and then recommend it to you. In this case, the videos that you liked previously will be the features or the data that the model will train. On the other hand, the videos that you most likely will want to watch (watched by other people who liked the same videos as you) will be the labels or the targets to the model/technique. The model/technique essentially tries and \"match\" the features to the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning techniques refer to machine learning algorithms that require the data to be labelled or have a target. A label or target refers to the goal that you want to achieve in the machine learning algorithm.\n",
    "\n",
    "For example, if you want to predict the exam scores of a student given the number of hours spent studying, then the data must contain the exam scores for each student. This will allow the machine learning algorithm to learn from the examples given. Another important term in supervised learning techniques is that of features. Features refer to the data that can be used to predict the target or label. Based on the example of the exam scores, the exam scores are the target and the number of hours spent studying is a feature. Other features for that example can include the number of questions practiced, amount of sleep before the exam, etc. \n",
    "\n",
    "With the features and labels/targets, the algorithm will then be able to \"learn\" the relationship between the features and labels/targets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the articles https://towardsdatascience.com/explaining-supervised-learning-to-a-kid-c2236f423e0f and https://www.geeksforgeeks.org/supervised-unsupervised-learning/, and watch this [video](https://www.youtube.com/watch?v=cfj6yaYE86U) and answer the questions listed below in your worksheet. Pay more attention to supervised learning. It is ok if you do not understand unsupervised learning at this point.\n",
    "\n",
    "- Explain supervised learning in your own words.\n",
    "- Explain and give examples of the terms: features, labels/targets, machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning techniques can be used to either classify data into different groups or to predict the relationships between variables. Techniques that classify data return categories or groups. For example, if we want to predict whether there will be rain tomorrow, we can use an algorithm that will return categories such as raining or sunny. On the other hand, techniques that are used for regression return numerical solutions. For example, if we want to predict the amount of rain tomorrow, we can use an alogrithm than will return numbers instead of categories.\n",
    "\n",
    "Read this [article](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/) and watch this [video](https://www.youtube.com/watch?v=f7YB73F0zDo) to find out more information about difference between classification and regression. While reading the article and watching the video, try to think of some scenarios where you will use classification and also some scenarios where you will use regression. List these scenarios in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding what is supervised learning, we will now explore the different supervised learning techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the graph! These are the height and weight samples of male and female. Notice how they are grouped together. Males tend to be taller and heavier as compared to females, and you can see that there is a noticeable grouping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/KNN1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the green dot, the unknown input. Looking at the data, would you say that the unknown input belong to the male data or the female data? Why? How would you determine that?\n",
    "\n",
    "Well, you can see that they are closer to the male data, and thus it is more likely that the unknown data represents a male as well. This method of determining a group by its distance to other, already known data points, is called the K-nearest neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbours (KNN) can be used in classification or regression problems. However, it is mainly used for classification problems. As the name suggests, this algorithm relies on the surrounding points or neighbours to determine its class or group. For example, if you are trying to classify an unknown point as either class A or class B using KNN and the majority of the points nearest to the unknown point are in class A, which class do you think the unknown point will be in?\n",
    "\n",
    "If you guessed class A, your answer is right. This is because KNN utilises the properties of the majority of the nearest points to decide how to classify unknown points. This is similar to the famous phrase \"birds of the same feather, flock together\". Likewise, you will expect points that are similar to be close to each other.\n",
    "\n",
    "Watch this [video](https://www.youtube.com/watch?v=MDniRwXizWo) to find out more about KNN. What are the main advantages and disadvantages of KNN? You will be using KNN in subsequent exercises. This is because it is an easy to use and flexible algorithm which can be used for many problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding how KNN works, lets try to apply it to a hypothetical scenario. In this scenario, you want to predict if a device is a laptop or a computer using features such as price and amount of memory. As such, you plotted a scatter plot for all the data points that you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./resources/KNN.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x-axis shows the amount of memory (GB) whereas the y-axis shows the price (USD). The blue circles are data points for desktop whereas the orange circles are data points for laptops. The star represents the unknown point.\n",
    "\n",
    "Based on your understanding of KNN, will the unknown point be a desktop or laptop if we were to apply KNN with 3 nearest neighbours? Will your answer change if you were to use 4 nearest neighbours or 5 nearest neighbours? How about if you were to use 9 nearest neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you realise that the unknown point will change its classification if you were to use 9 nearest neighbours? From the graph, it is quite obvious that the unknown point is not a desktop. However, due to KNN using the majority, it is possible for KNN to wrongly classify an unknown point if the wrong number of nearest neighbours were used. Thus, it is always important to identify the best number of nearest neighbours. We will see how this is done in the next few workshops when we learn how to tune the models! For now, it is sufficicent to just understand why the number of neighbours is an important parameter in K nearest neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now apply the KNN technique to the Iris Flower dataset. First, load the previously used Iris Flower dataset as a pandas dataframe. Download the file from this [link](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/) if you did not download the dataset previously. The file to download is the iris.data file. You can refer to the picture (source: https://www.researchgate.net/figure/Trollius-ranunculoide-flower-with-measured-traits_fig6_272514310) below for more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/PetalSepal1.PNG\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "1           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "2           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "3           5.0          3.6           1.4          0.2  Iris-setosa\n",
       "4           5.4          3.9           1.7          0.4  Iris-setosa"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # open csv file\n",
    " # add column names\n",
    " # print the first five rows to check dataset\n",
    "\n",
    "#your code here\n",
    "df = pd.read_csv(\"iris.data\")\n",
    "names = [\"sepal_length\", \"sepal_width\",\"petal_length\",\"petal_width\", \"class\"]\n",
    "df.columns = names\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to use KNN to classify the dataset with the type of flower or class being the target variable. Before we can do so, we need to convert the categorical classes into numbers which can be understood by the computer. We can do so through the usage of label encoding. Label encoding refers to the assignment of a number for each category. For example, if you have to predict the weather and there are two classes, rainy or sunny, we can label rainy as 0 and sunny as 1 (see table below). In this way, we can convert the categories to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./resources/Label2.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the class/flower type in the Iris Flower dataset into numbers. What are the different classes within the dataset? How many classes are there in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, label encode the different classes. 'Iris-setosa' can be 1, 'Iris-versicolor' can be 2 and 'Iris-virginica' can be 3. The code below will encode for one of the classes. Edit the code to encode for all the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    50\n",
      "2    50\n",
      "1    49\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=int64)' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-31b8988fee60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Use .replace to change the different classes into numbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_encode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   3796\u001b[0m                                               \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3797\u001b[0m                                               \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3798\u001b[1;33m                                               method=method)\n\u001b[0m\u001b[0;32m   3799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3800\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shift'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5801\u001b[0m             return self.replace(to_replace, value, inplace=inplace,\n\u001b[1;32m-> 5802\u001b[1;33m                                 limit=limit, regex=regex)\n\u001b[0m\u001b[0;32m   5803\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   3796\u001b[0m                                               \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3797\u001b[0m                                               \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3798\u001b[1;33m                                               method=method)\n\u001b[0m\u001b[0;32m   3799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3800\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shift'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5819\u001b[0m                                                     \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5820\u001b[0m                                                     \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5821\u001b[1;33m                                                     regex=regex)\n\u001b[0m\u001b[0;32m   5822\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5823\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   3430\u001b[0m         return super(Series, self).replace(to_replace=to_replace, value=value,\n\u001b[0;32m   3431\u001b[0m                                            \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3432\u001b[1;33m                                            regex=regex, method=method)\n\u001b[0m\u001b[0;32m   3433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3434\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'shift'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mreplace\u001b[1;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[0;32m   5849\u001b[0m                                                        \u001b[0mdest_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5850\u001b[0m                                                        \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5851\u001b[1;33m                                                        regex=regex)\n\u001b[0m\u001b[0;32m   5852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5853\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# [NA, ''] -> 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mreplace_list\u001b[1;34m(self, src_list, dest_list, inplace, regex, mgr)\u001b[0m\n\u001b[0;32m   3737\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_maybe_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asm8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3737\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_maybe_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asm8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3739\u001b[1;33m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3741\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcomp\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m   3735\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3736\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3737\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_maybe_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asm8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\testAI\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_maybe_compare\u001b[1;34m(a, b, op)\u001b[0m\n\u001b[0;32m   5163\u001b[0m         raise TypeError(\n\u001b[0;32m   5164\u001b[0m             \"Cannot compare types {a!r} and {b!r}\".format(a=type_names[0],\n\u001b[1;32m-> 5165\u001b[1;33m                                                           b=type_names[1]))\n\u001b[0m\u001b[0;32m   5166\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
     ]
    }
   ],
   "source": [
    "# Print number of data points in each class\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Dictionary to input the different numbers for different classes\n",
    "label_encode = {\"class\": {\"Iris-setosa\":1,\"Iris-versicolor\":2,\"Iris-virginica\":3}}\n",
    "\n",
    "# Use .replace to change the different classes into numbers\n",
    "df.replace(label_encode,inplace=True)\n",
    "df\n",
    "\n",
    "\n",
    "# Print number of data points in each class to check if the classes have changed to numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Bonus: There is also another method to convert categories to numbers. The method is known as one-hot encoding. One-hot encoding changes the categories into binary (0 or 1) categories. For example, if you have raining or sunny days as categories, one hot encoding will add 2 more columns, rainy and sunny, to the dataframe. If the data point shows rainy, it will be converted to a value of 1 under the raining column and a value of 0 under the sunny column (see table below). Read this [article](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) to find out more about one-hot encoding. Now, read this [article](http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example) to learn how to do one-hot encoding for pandas. Import the Iris Flower dataset again as df2 and conduct the one-hot encoding for it.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/Label1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>class_Iris-setosa</th>\n",
       "      <th>class_Iris-versicolor</th>\n",
       "      <th>class_Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.1  3.5  1.4  0.2  class_Iris-setosa  class_Iris-versicolor  \\\n",
       "0    4.9  3.0  1.4  0.2                  1                      0   \n",
       "1    4.7  3.2  1.3  0.2                  1                      0   \n",
       "2    4.6  3.1  1.5  0.2                  1                      0   \n",
       "3    5.0  3.6  1.4  0.2                  1                      0   \n",
       "4    5.4  3.9  1.7  0.4                  1                      0   \n",
       "5    4.6  3.4  1.4  0.3                  1                      0   \n",
       "6    5.0  3.4  1.5  0.2                  1                      0   \n",
       "7    4.4  2.9  1.4  0.2                  1                      0   \n",
       "8    4.9  3.1  1.5  0.1                  1                      0   \n",
       "9    5.4  3.7  1.5  0.2                  1                      0   \n",
       "10   4.8  3.4  1.6  0.2                  1                      0   \n",
       "11   4.8  3.0  1.4  0.1                  1                      0   \n",
       "12   4.3  3.0  1.1  0.1                  1                      0   \n",
       "13   5.8  4.0  1.2  0.2                  1                      0   \n",
       "14   5.7  4.4  1.5  0.4                  1                      0   \n",
       "15   5.4  3.9  1.3  0.4                  1                      0   \n",
       "16   5.1  3.5  1.4  0.3                  1                      0   \n",
       "17   5.7  3.8  1.7  0.3                  1                      0   \n",
       "18   5.1  3.8  1.5  0.3                  1                      0   \n",
       "19   5.4  3.4  1.7  0.2                  1                      0   \n",
       "20   5.1  3.7  1.5  0.4                  1                      0   \n",
       "21   4.6  3.6  1.0  0.2                  1                      0   \n",
       "22   5.1  3.3  1.7  0.5                  1                      0   \n",
       "23   4.8  3.4  1.9  0.2                  1                      0   \n",
       "24   5.0  3.0  1.6  0.2                  1                      0   \n",
       "25   5.0  3.4  1.6  0.4                  1                      0   \n",
       "26   5.2  3.5  1.5  0.2                  1                      0   \n",
       "27   5.2  3.4  1.4  0.2                  1                      0   \n",
       "28   4.7  3.2  1.6  0.2                  1                      0   \n",
       "29   4.8  3.1  1.6  0.2                  1                      0   \n",
       "..   ...  ...  ...  ...                ...                    ...   \n",
       "119  6.9  3.2  5.7  2.3                  0                      0   \n",
       "120  5.6  2.8  4.9  2.0                  0                      0   \n",
       "121  7.7  2.8  6.7  2.0                  0                      0   \n",
       "122  6.3  2.7  4.9  1.8                  0                      0   \n",
       "123  6.7  3.3  5.7  2.1                  0                      0   \n",
       "124  7.2  3.2  6.0  1.8                  0                      0   \n",
       "125  6.2  2.8  4.8  1.8                  0                      0   \n",
       "126  6.1  3.0  4.9  1.8                  0                      0   \n",
       "127  6.4  2.8  5.6  2.1                  0                      0   \n",
       "128  7.2  3.0  5.8  1.6                  0                      0   \n",
       "129  7.4  2.8  6.1  1.9                  0                      0   \n",
       "130  7.9  3.8  6.4  2.0                  0                      0   \n",
       "131  6.4  2.8  5.6  2.2                  0                      0   \n",
       "132  6.3  2.8  5.1  1.5                  0                      0   \n",
       "133  6.1  2.6  5.6  1.4                  0                      0   \n",
       "134  7.7  3.0  6.1  2.3                  0                      0   \n",
       "135  6.3  3.4  5.6  2.4                  0                      0   \n",
       "136  6.4  3.1  5.5  1.8                  0                      0   \n",
       "137  6.0  3.0  4.8  1.8                  0                      0   \n",
       "138  6.9  3.1  5.4  2.1                  0                      0   \n",
       "139  6.7  3.1  5.6  2.4                  0                      0   \n",
       "140  6.9  3.1  5.1  2.3                  0                      0   \n",
       "141  5.8  2.7  5.1  1.9                  0                      0   \n",
       "142  6.8  3.2  5.9  2.3                  0                      0   \n",
       "143  6.7  3.3  5.7  2.5                  0                      0   \n",
       "144  6.7  3.0  5.2  2.3                  0                      0   \n",
       "145  6.3  2.5  5.0  1.9                  0                      0   \n",
       "146  6.5  3.0  5.2  2.0                  0                      0   \n",
       "147  6.2  3.4  5.4  2.3                  0                      0   \n",
       "148  5.9  3.0  5.1  1.8                  0                      0   \n",
       "\n",
       "     class_Iris-virginica  \n",
       "0                       0  \n",
       "1                       0  \n",
       "2                       0  \n",
       "3                       0  \n",
       "4                       0  \n",
       "5                       0  \n",
       "6                       0  \n",
       "7                       0  \n",
       "8                       0  \n",
       "9                       0  \n",
       "10                      0  \n",
       "11                      0  \n",
       "12                      0  \n",
       "13                      0  \n",
       "14                      0  \n",
       "15                      0  \n",
       "16                      0  \n",
       "17                      0  \n",
       "18                      0  \n",
       "19                      0  \n",
       "20                      0  \n",
       "21                      0  \n",
       "22                      0  \n",
       "23                      0  \n",
       "24                      0  \n",
       "25                      0  \n",
       "26                      0  \n",
       "27                      0  \n",
       "28                      0  \n",
       "29                      0  \n",
       "..                    ...  \n",
       "119                     1  \n",
       "120                     1  \n",
       "121                     1  \n",
       "122                     1  \n",
       "123                     1  \n",
       "124                     1  \n",
       "125                     1  \n",
       "126                     1  \n",
       "127                     1  \n",
       "128                     1  \n",
       "129                     1  \n",
       "130                     1  \n",
       "131                     1  \n",
       "132                     1  \n",
       "133                     1  \n",
       "134                     1  \n",
       "135                     1  \n",
       "136                     1  \n",
       "137                     1  \n",
       "138                     1  \n",
       "139                     1  \n",
       "140                     1  \n",
       "141                     1  \n",
       "142                     1  \n",
       "143                     1  \n",
       "144                     1  \n",
       "145                     1  \n",
       "146                     1  \n",
       "147                     1  \n",
       "148                     1  \n",
       "\n",
       "[149 rows x 7 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"iris.data\")\n",
    "\n",
    "df2= pd.get_dummies(df, prefix=['class'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now try out the KNN algorithm after the categorical values have been converted by label encoding. We first have to import the KNN algorithm from sklearn. Sklearn is an open source python library which contains numerous popular machine learning algorithms. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read this [link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to find out how to use the KNeighborsClassifier from sklearn. Do you remember from earlier in this notebook that the number of neighbours is required for KNN? From the link, what is the default number of neighbors used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the default number of neighbors to try and classify the Iris Flower dataset. We will only use 2 features (sepal_length and sepal_width) initially. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width\n",
      "0           4.9          3.0\n",
      "1           4.7          3.2\n",
      "2           4.6          3.1\n",
      "3           5.0          3.6\n",
      "4           5.4          3.9\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: int64\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Initialise the KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df[['sepal_length','sepal_width']]\n",
    "y = df['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "\n",
    "# Train KNN using the x and y values. This is done through the .fit method.\n",
    "KNN = KNN.fit(x,y)\n",
    "\n",
    "# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\n",
    "test = pd.DataFrame()\n",
    "test['sepal_length'] = [5]\n",
    "test['sepal_width'] = [3]\n",
    "predict_flower = KNN.predict(test)\n",
    "\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, do you know which flower type was predicted for a data point with sepal length = 5 and sepal width = 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! What if the sepal length = 3 and sepal width = 5? Edit the code above to find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width\n",
      "0           4.9          3.0\n",
      "1           4.7          3.2\n",
      "2           4.6          3.1\n",
      "3           5.0          3.6\n",
      "4           5.4          3.9\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: class, dtype: int64\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "# Initialise the KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df[['sepal_length','sepal_width']]\n",
    "y = df['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "\n",
    "# Train KNN using the x and y values. This is done through the .fit method.\n",
    "KNN = KNN.fit(x,y)\n",
    "\n",
    "# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\n",
    "test = pd.DataFrame()\n",
    "test['sepal_length'] = [3]\n",
    "test['sepal_width'] = [5]\n",
    "predict_flower = KNN.predict(test)\n",
    "\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have trained your first supervised learning model. However, we only used 2 variables. Train another KNN model named KNN2 with all the other variables instead of just sepal length and sepal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width\n",
      "0           4.9          3.0           1.4          0.2\n",
      "1           4.7          3.2           1.3          0.2\n",
      "2           4.6          3.1           1.5          0.2\n",
      "3           5.0          3.6           1.4          0.2\n",
      "4           5.4          3.9           1.7          0.4\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: class, dtype: object\n",
      "['Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "# Initialise the KNeighborsClassifier\n",
    "KNN = KNeighborsClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y = df['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "\n",
    "# Train KNN using the x and y values. This is done through the .fit method.\n",
    "KNN = KNN.fit(x,y)\n",
    "\n",
    "# Let us use the trained KNN to predict the type of flower if its sepal length = 5 and sepal_width = 3 We can use the .predict method to do so.\n",
    "test = pd.DataFrame()\n",
    "test['sepal_length'] = [5.8]\n",
    "test['sepal_width'] = [2.3]\n",
    "test['petal_length'] = [5]\n",
    "test['petal_width'] = [1.3]\n",
    "predict_flower = KNN.predict(test)\n",
    "\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your new model, can you predict the flower type with sepal_length = 5.8, sepal_width = 2.3, petal_length = 5.0 and petal_width = 1.3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another supervised machine learning technique is the decision tree. Watch this [video](https://www.youtube.com/watch?v=eKD5gxPPeY00) to find out more about decision trees. Decision trees can be used for classification or regression. The trees split the dataset into smaller and smaller groups. The splitting of groups is based on decision points in the tree. After watching, draw an example of a decision tree in your worksheet. You can refer to the example shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/dt1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use any decision tree, we first have to train the model with data. During the training process, the algorithm will split the dataset based on certain parameters such as entropy or gini. For now, you do not need to know how to compute these parameters as the algorithm will compute it for you. You can search for the calculation online if you want to learn more about decision trees. After the training process, the decision tree will \"remember\" the decision points and apply them to any new set of data to predict its classification. Let us now try to classify the Iris Flower dataset using a decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to import the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use the same df dataframe from earlier in this notebook. The df dataframe contains the Iris Flower dataset and the outputs have been label encoded. We will first use the sepal length and sepal width as x values and the class as the targets/outputs or y values. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width\n",
      "0           4.9          3.0\n",
      "1           4.7          3.2\n",
      "2           4.6          3.1\n",
      "3           5.0          3.6\n",
      "4           5.4          3.9\n",
      "0    Iris-setosa\n",
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "Name: class, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Initialise the Decision Tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Extract out the x values and y values. x will be sepal_length and y will be classes\n",
    "x = df[['sepal_length','sepal_width']]\n",
    "y = df['class']\n",
    "\n",
    "# Print .head() of x and y to make sure the data is correct\n",
    "print(x.head())\n",
    "print(y.head())\n",
    "\n",
    "# Train decision tree using the x and y values. This is done through the .fit method.\n",
    "dt = dt.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we use the DecisionTreeClassifier instead of the DecisionTreeRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you make a prediction using the trained tree? Can you predict the type of flower if its sepal length = 5 and sepal_width = 3? You can use the .predict method to do so. Edit the code below to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe called test2 with sepal_length and sepal_width as its columns. Sepal_length has been done for you in the code below.\n",
    "test2 = pd.DataFrame()\n",
    "test2['sepal_length'] = [5]\n",
    "test2['sepal_width'] = [3]\n",
    "\n",
    "# Use the .predict method to predict the new flower. You can call the predicted flower as predict_flower.\n",
    "predict_flower = dt.predict(test2)\n",
    "\n",
    "# Print predict_flower\n",
    "print(predict_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the predicted flower type and does it match with that predicted by K nearest neighbours earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train a new decision tree, dt2, based on sepal length, sepal width, petal length and petal width. Predict the flower type with sepal_length = 5.8, sepal_width = 2.3, petal_length = 5.0 and petal_width = 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the flower type predicted by the new tree? Is it the same as that predicted by K-Nearest Neighbours?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can see that while most machine learning techniques may be used to solve the same problem, the outcome/predictions may differ across models! As such, there is a need to choose which models to use based on the accuracy of the models. You will learn how to evaluate the quality of the models in the later workshops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
