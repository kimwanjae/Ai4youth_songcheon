{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised machine learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised data refers to data that do not have any labels or targets. This is unlike supervised data that has a target or a goal to find. As no targets are given for unsupervised data, the unsupervised machine learning technique has to be able to find interesting patterns within the data on its own.\n",
    "\n",
    "For example, imagine that you were told to split your current classmates into different groups, what will be the different ways to group your classmates? Spend some time to think about this and list the different ways down in the cell below. After writing down your answers, share it with the class to see if everyone has the same answers as you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your methods of spliting exactly the same as the rest of the class?\n",
    "\n",
    "The answer is most likely no. This is because there are many ways to split the group and no specific way or target was provided. This problem is essentially an unsupervised learning problem whereby you do not know the exact way to split the group but will still be able to split them through information that you found within the group. Thus, an unsupervised machine learning algorithm has to be able to find patterns within the data without any prior information.\n",
    "\n",
    "One common unsupervised machine learning problem is the classification of shoppers through the items that they purchased. By classifying these shoppers using unsupervised learning, the shop or store will be able to identify the different groups of shoppers (high spenders, low spenders, shoppers who only purchase clothes, shoppers who only purchase groceries, etc). \n",
    "\n",
    "Another unsupervised machine learning problem is the potential relatioinship between human health and the environment. Through unsupervised learning, you may be able to identify if residents staying in certain regions within a country are more prone to certain illnesses. This may help identify underlying reasons such as poor air quality or unsanitary living conditions.\n",
    "\n",
    "Are you able to identify other common unsupervised machine learning problems that may have a social impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try to implement an unsupervised machine learning technique known as hierarchical clustering on an actual unsupervised dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wholesale customer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the wholesale customer dataset that can be obtained from [here](https://archive.ics.uci.edu/ml/datasets/Wholesale+customers#). Download the data and import it in as a dataframe df in the cell below. Remember to check for simple statistics such as the number of samples, mean value and standard deviation (do you remember the command for this?). Also check if the data has any anomalous or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any missing data points or potentially erroneous data points in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, do you know the column names? What do the column names represent? You can refer to the website where you downloaded the dataset for more information. Hint: m.u refers to monetary units for the country (you need not know which currency it belongs to)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the columns, we can see that 6 columns have purchase or spending data whereas 2 columns (channel and region) are related to locations rather than spending. Thus, which will be the columns that we want to use if we want to look only at spending?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As such, we will now drop the columns (Channel and Region) that we do not want. The code below will drop 1 of the columns. Expand the code to drop the other column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "df2 = df.drop(['Channel'],axis=1)\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets relook the basic statistics again for the new dataframe df2. Print the basic statstics and compare the mean and percentile values. Are the mean and all the percentile values thes same for all the 6 columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the differences in the mean and percentile values (25%, 50% and 75%), we can observe that the distribution of the data is different for all 6 variables. As such, it will be hard to cluster the data if the distribution of all the variables are different as it will be difficult to identify similarities. For example, if a variable has values that spread between 0 and 100 and another variable that has values that spread between 1000 and 2000, then it will be hard to directly compare these variables. Therefore, we will need to standardise or normalise the data for all 6 columns before we can conduct the classification. As a good practice, we will always standardise or normalise all the datasets before we apply any machine learning technique to the dataset. Read this [article](https://medium.com/greyatom/why-how-and-when-to-scale-your-features-4b30ab09db5e) and write down the formula in your worksheet to standardise or normalise the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply standardisation to the dataset. We can use pre-build python functions to help us do so. One such function will be that of [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Import StandardScaler above (Remember, it is good practice to import all your required modules together at the start of the notebook) and apply it to the dataframe df2. In this case, you can use the .fit_transform() method to do so. Edit the code below to complete the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise StandardScaler\n",
    "Scale = StandardScaler()\n",
    "\n",
    "# Fit_transform the data directly and assign it to another variable\n",
    "df2_scaled = Scale.fit_transform(????????)\n",
    "\n",
    "# Conver the output from a numpy array into a pandas dataframe\n",
    "df2_scaled = pd.DataFrame(df2_scaled, index=df2.index, columns=df2.columns)\n",
    "\n",
    "# Print basic statistics again for comparison\n",
    "print(df2_scaled.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above printout, observe and compare the mean, standard deviation and percentile values for all 6 categories. Are these values now similar for all 6 columns? What is the mean value and standard deviation that you should expect after standardisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us try to cluster the dataset. As it is an unsupvervised machine learning problem, we can use an unsupervised learning technique known as hierarchical clustering. Read this [article](https://www.displayr.com/what-is-hierarchical-clustering/) and watch this [video](https://www.youtube.com/watch?v=EUQY3hL38cw) for more information. What is the output from the hierarchial clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dendrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding hierarchical clustering, let us try to cluster the dataset based on only the purchases on Fresh, Milk and Grocery. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required functions\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Extract the first 3 columns into another dataframe\n",
    "df2_test = df2_scaled[['Fresh','Milk','Grocery']]\n",
    "\n",
    "# Print the column headers to check if they are correct\n",
    "print(df2_test.head())\n",
    "\n",
    "# Setup the linkage as complete linkage. You can search for other linkages. For now, we can use complete.\n",
    "link = linkage(df2_test,'complete')\n",
    "\n",
    "# Plot out the dendrogram based on the linkage. Truncate_mode = 'lastp' will only show the top portion of the dendrogram. You can remove it to see the difference\n",
    "plt.figure()\n",
    "dendrogram(link,truncate_mode='lastp')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the dendrogram, are we able to decide how many clusters the data should be clustered into? This is one of the main features of hierarchical clustering. It will be able to identify the number of groups that the data can be clustered into. Read this [article](https://medium.com/@iSunilSV/data-science-python-hierarchical-clustering-fbf54d274dc6) to find out how to determine the best number of clusters from the dendrogram and apply the technique to the dendrogram above. The idea is to find the longest vertical line that does not cut any other horizontal line and then draw a horizontal line across. How many clusters should we cluster the dataset into?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is done through visual inspection, we expect the number of clusters to be slightly different from person to person. From the figure below, we can see that the longest vertical line not cutting any other horizontal line should be the blue line on the left. Thus, we will find the base of that vertical line and draw a horizontal line (black line) across. You will see that the black line will cut 6 vertical lines in total. Thus, there should be 6 clusters in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/HC.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, it is your turn to try the hierarchical clustering for the all 6 columns instead of just 3 columns. How many clusters should the full dataset be clustered into?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = blue>Bonus: Are you able to find other techniques that can also be used for unsupervised learning? Read this [article](https://medium.com/machine-learning-for-humans/unsupervised-learning-f45587588294) for a start and you can also search for more information about the other techniques on the internet. List down any interesting information that you found in the cell below!</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
