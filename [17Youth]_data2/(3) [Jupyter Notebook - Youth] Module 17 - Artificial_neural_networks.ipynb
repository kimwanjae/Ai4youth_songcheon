{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you ever wondered how we process and learn information? For example, how does our body process information such that we are able to move our hands or legs? To put it simply, the brain will process information and then send out signals to the rest of the body to trigger certain muscle movements. These signals are transported through the nervous system. One of the main components of the nervous system are neuron cells. These cells work on a threshold basis which means that the signal will only be transferred from cells to cells if it is higher than a certain value or amount. As such, when we decide to move our hands, the signals from the brain will get transferred to the muscle in our hands and not the muscle in our legs.\n",
    "\n",
    "However, this only explains how we process information. How about the ability of humans to learn? For example, why do we know to stop at a red light or how to kick a ball? It is because we were trained to do so by looking at examples or how other people were doing it. Through these examples, we were able to learn and remember.\n",
    "\n",
    "Based on the above, would it be great if computers were able to mimic the way humans process and learn information? As such, the concept of artificial neural networks were developed. Artificial neural networks are able to 'learn' complex relationships within datasets. An illustration of a simple neural network is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/ANN.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The illustration above shows a simple neural network with 1 input layer, 1 hidden layer (in between an input layer and an output layer) and 1 output layer. Each circle represent 1 node or 1 neuron. We usually do not discuss the number of nodes at the input layer within the model architeture as the input layer is just the data that is being passed to the model. Thus, the hidden layer has 4 nodes/neurons and the output layer has 1 node/neuron. \n",
    "\n",
    "The output layer will show the results of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the neural network work? How can they be useful for machine learning project? Watch this [video](https://www.youtube.com/watch?v=aircAruvnKk) to find out more about artificial neural networks. Pause the video and take time to try and understand how the neural network works. If in doubt, try to approach the teacher to clarify your doubts. Note down any interesting information on neural networks on your worksheet. Are you also able to draw out the network (similar to the illustration above) if the network has 1 input layer with 5 nodes, 2 hidden layers with 3 nodes each and 1 output layer with 2 nodes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding the different features of an artificial neural network, one question that still remains is how does the network \"learn\"?\n",
    "\n",
    "Take for example a young basketball player who is learning to shoot a 3-point shot. If he shoots and he misses because the shot is too short, the basketball player will adjust and increase the strength of the next shot. If the next shot now is too far right of the basket, the player will again adjust his shot to shoot more towards the center. The player continues to do this until the shot is made. The player then remembers the exact strength and shot direction when shooting 3-point shots in future.\n",
    "\n",
    "This is similar to how neural networks are trained. First, the data is passed through the network and a predicted output is given. This is known as a forward propagation. The predicted output is then compared to the actual output of the data and the differences between the predicted and actual will be passed backwards through the model. During the backward pass, adjustments will be made within the model such that the differences between prediction output and actual output will be reduced. This is known as the backpropagation. After the adjustments have been made, data will be passed through from the input layer again and another predicted output will be made. The new predicted output will be compared to the actual output again and the differences will be passed backwards through the model. More adjustments will be made within the model.\n",
    "\n",
    "Thus, the process of forward propagation and backpropagation will be repeated until the differences between predicted output and the actual output are minimised. The model is now trained and can be used for prediction of other similar datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of another example in your life that is similar to the way the neural networks work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example to help you understand neural networks better. You have been tasked to bake a cake for your father's birthday. You follow the basic cookbook and come up with a basic cake. As you want your cake to be the best cake anyone has eaten, you approach your mother for a taste test. Your mother replies that the cake is too sweet and slightly burnt. Thus, you try and adjust the amount of sugar and also the time the cake spent in the oven. Next, you will then bake another cake with your new recipe and baking time before doing another taste test with your mother. This continues until you get the perfect cake.\n",
    "\n",
    "The first steps to bake the cake are similar to the forward propagation step within the artificial neural network. The taste test is similar to the comparison of a predicted output to the actual output. The adjustment of the amount of sugar and baking time is similar to backpropagation within the neural network. The repetition in the steps are similar to the full training process of the model.\n",
    "\n",
    "To have a better visualisation of how backpropagation works, watch this [video](https://www.youtube.com/watch?v=Ilg3gGewQ5U) and take down any information that interests you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>Bonus: You are not required to understand the actual adjustments within the model. However, if you are mathematically inclined or really interested in understanding all the adjustments and have time, you can watch the 2 videos listed below. Note down any interesting information in your worksheet or the cell below. </font>\n",
    "- [video 1](https://www.youtube.com/watch?v=IHZwWFHWa-w)\n",
    "- [video 2](https://www.youtube.com/watch?v=tIeHLnjs5U8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a neural network with the Iris Flower dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Iris Flower dataset as a dataframe df below. The file should be iris.data. Remember to include the headers for all the columns. You can refer to the picture (source: https://www.researchgate.net/figure/Trollius-ranunculoide-flower-with-measured-traits_fig6_272514310) below to understand the variables. Check for any missing values or erroneous data. Are there any missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./resources/PetalSepal1.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#your code here\n",
    "#Import the Iris Flower dataset as a dataframe df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have to split the datset into the x values (features which the model can learn relationships from) and the y values (target values or expected output from the model). Additionally, we also have to standardise the dataset. This is to allow neural networks to classify easily. The code below will extract out the x values as x_values and also standardise the values. We will extract the y_values later. Run the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "print(x_values.head())\n",
    "standardise = StandardScaler()\n",
    "x_values = standardise.fit_transform(x_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now build a simple neural network. In order to do so, we will need to import the dense and sequential functions from keras library. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build a neural network with 1 input layer, 2 hidden layers and 1 output layer. There are no rules to decide how many nodes should be within the hidden layers. For this neural network, we will use 6 hidden nodes for each hidden layer. With regards to the output layer, we should use as many nodes as the number of classes. How many nodes should we use for the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the code below to build the artificial neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the neural network as model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 6 nodes. Input_dim refers to the number of columns/number of features in x_values or the input layer.\n",
    "# Activation refers to how the nodes/neurons are activated. We will use relu. Other common activations are 'sigmoid' and 'tanh'\n",
    "model.add(Dense(6,input_dim=4,activation='relu'))\n",
    "\n",
    "# Add the hidden layer with 6 nodes. \n",
    "model.add(Dense(6,activation='relu'))\n",
    "\n",
    "# Add the output layer with 3 nodes. The activation used has to be 'softmax'. Softmax is used when you are dealing with categorical outputs or targets. \n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# Compile the model together. The optimizer refers to the method to make the adjustment within the model. Loss refers to how the difference between the predicted out \n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also print out the model summary after it has been compiled. Try the code below to see the layers within the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the y_values are categorical in nature (categories instead of numbers), we have to convert the y_values from categories into numbers before we can train the neural network. For neural networks, if the categories are not numerical groups (for example, 1,2,3,4,etc) we have to perform label encoding (Remember doing this in an earlier notebook?) before doing one-hot encoding. Refer to the bonus section in the \"Supervised learning technique\" notebook for more information on one-hot encoding. You can also read this [article](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) to find out more. We can use the to_categorical function from Keras to help us do so. Try the code below to label encode then one-hot encode the y_values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Print number of data points in each class\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Dictionary to input the different numbers for different classes. \n",
    "# We are using values starting from 0 so that only 3 instead of 4 columns will be created in by the one-hot encoding.\n",
    "label_encode = {\"class\": {\"Iris-setosa\":0, \"Iris-versicolor\":1, \"Iris-virginica\":2}}\n",
    "\n",
    "# Use .replace to change the different classes into numbers\n",
    "df.replace(label_encode,inplace=True)\n",
    "\n",
    "# Print number of data points in each class to check if the classes have changed to numbers\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Extract out the class as y_values\n",
    "y_values = df['class']\n",
    "\n",
    "# One-hot encode the y_values\n",
    "y_values = to_categorical(y_values)\n",
    "\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us train the model. Run the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with x_values and y_values. Epochs refer to the number of times the full dataset will be used to train the model.\n",
    "# Shuffle = True tells the model to randomise the arrangement of the dataset after each epoch. This will allow the model to learn.\n",
    "model.fit(x_values,y_values,epochs=20,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! You have trained your first neural network. Before we look at the accuracy, we have to understand some of the terms in the output.\n",
    "\n",
    "Epochs refer to the number of times the full dataset will be used to train the model.\n",
    "us/step shows how long the model took to train on each epoch.\n",
    "acc shows how accurate the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the model above, you can see that the model accuracy is about 74%. Try to see if you can get a better accuracy by adding another hidden layer to the model. The additional hidden layer can have the same number of nodes as the previous layer. Copy the relevant codes listed above in the cell below and modify the codes to add in the additional hidden layer. Train the new model and see if the accuracy improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding another hidden layer, you should observe that the accuracy seems to be lower than the initial model. As such, this shows that adding more layers need not necessarily lead to a higher accuracy.\n",
    "\n",
    "<font color = blue>Bonus: You can try other methods to improve the accuracy. How about increasing the number of nodes in the hidden layer? Do you get a higher accuracy if you do so?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the neural network can be trained for any number of epochs. This means that the network can keep learning from the same dataset many times. What do you think will happen if the model keeps learning from the same dataset? Do you think the network will be able to obtain very high accuracy by doing so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You were right if you think that the model's accuracy will increase as it continues to learn. You can try it on the same dataset. Run the code below and observe the accuracy. Is it higher than the accuracy from the previous model with the same setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the neural network as model\n",
    "model4 = Sequential()\n",
    "\n",
    "# Add the first hidden layer with 6 nodes. Input_dim refers to the number of columns/number of features in x_values or input_layer.\n",
    "# Activation refers to how the nodes/neurons are activated. We will use relu. Other common activations are 'sigmoid' and 'tanh'\n",
    "model4.add(Dense(6,input_dim=4,activation='relu'))\n",
    "\n",
    "# Add the hidden layer with 6 nodes. \n",
    "model4.add(Dense(6,activation='relu'))\n",
    "\n",
    "# Add the output layer with 3 nodes. The activation used has to be 'softmax'. Softmax is used when you are dealing with categorical outputs or targets. \n",
    "model4.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# Compile the model together. The optimizer refers to the method to make the adjustment within the model. Loss refers to how the difference between the predicted out \n",
    "model4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train model with x_values and y_values. Epochs refer to the number of times the full dataset will be used to train the model.\n",
    "# Shuffle = True tells the model to randomise the arrangement of the dataset after each epoch. This will allow the model to learn.\n",
    "model4.fit(x_values,y_values,epochs=200,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe from the printout that the accuracy score is now above 90%. Wow! It seems amazing that just increasing the number of epochs will allow the accuracy to increase. Do you think it is good that the model is so highly accuracte on the data that it has trained on? Just imagine, will a soccer player do well in a match if he/she only trains extremely hard on scoring a goal from a specific spot on the field? Or will a baker be able to bake a delicious cake based on a customer's request if he/she only learns how to bake a cake that is a specific flavour, shape and size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soccer player will not perform well in a match as he/she may not be able to shoot accurately from other parts of the field. The baker will not be able to bake a delicious cake as he/she will only know 1 specific flavour.\n",
    "\n",
    "The idea behind this question is the concept of overfitting. If the model overfits, it will not be able to generalise to properly predict data that it has not seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the concept of overfitting and also applies to all machine learning techniques. Once the technique has fitted too acurrately on the dataset, the trained technique will not be able to generalise to other data that it has not seen before. As such, we usually only train the technique on a fraction of the dataset that we have and keep the remainder as a test or validation set to see if the model has overfitted. When training on the training set, the accuracy of the model on the test set should increase. However, at the point of overfitting, the accuracy on the test set will start to decrease. If you see that the test accuracy has begin to increase after a certain epoch, you should not train the model any further.\n",
    "\n",
    "Let us apply the split between a train and a test set to the dataset that we are using here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to decide how much data we want to keep and prevent the model from training on. Usually, we withold about 20% to 30% of the dataset. In this example, we will keep 25 percent of the dataset as the test/validation set. We can use the train_test_split function from the sklearn library. Try the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract out original x_values from the dataframe df. \n",
    "# We have to re-extract the x_values as the standardisation should only be based on the data that the model will train with.\n",
    "# Thus, we have to split the data first before standardising.\n",
    "x_values = df[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "\n",
    "# Test_size=0.25 indicates that 25% of the datapoints will be in x_test and y_test whereas 75% will be in x_train and y_train.\n",
    "# random_state=10 is used to ensure that the split is the same everytime you run the code below. \n",
    "# This is because the split is done randomly everytime. The same random_state is the only way to ensure the same split everytime.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_values,y_values,test_size=0.25,random_state=10)\n",
    "\n",
    "# Check the number of rows in x_train, x_test, y_train and y_test\n",
    "print(\"Number of rows in x_train:\", x_train.shape[0])\n",
    "print(\"Number of rows in x_test:\", x_test.shape[0])\n",
    "print(\"Number of rows in y_train:\", y_train.shape[0])\n",
    "print(\"Number of rows in y_test:\", y_test.shape[0])\n",
    "\n",
    "# We can now standardise the x values.\n",
    "# Initialise the StandardScaler\n",
    "standardise = StandardScaler()\n",
    "\n",
    "# Standardise the x_train values using .fit_transform\n",
    "x_train = standardise.fit_transform(x_train)\n",
    "\n",
    "# Standardise the x_test values using .transform. \n",
    "# There is no need to fit the data as the standardisation should be the same as that of x_train.\n",
    "x_test = standardise.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your own code to split the dataset into train and test/validation sets by witholding 20% of the dataset as test/validation set. Use x_train2, x_test2, y_train2 and y_test2 as your variables. Check that the number of rows are correct for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now use x_train2, x_test2, y_train2 and y_test2 to train a neural network. Write a code to create a neural network that has 2 hidden layers with 6 nodes each and 1 output layer with 3 nodes. The activation for the input hidden layer is 'relu' wheras the activation for the output layer is 'softmax'. The opitmizer to use is 'adam' and the loss should be 'categorical_crossentropy'. The metrics should be 'accuracy'. Use model_val as the model variable. Print the model summary after you compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train model_val using x_train and y_train. We will also test the accuracy after each epoch using x_test and y_test. Try the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with x_values and y_values. \n",
    "# Epochs refer to the number of times the full dataset will be used to train the model.\n",
    "# Shuffle = True tells the model to randomise the arrangement of the dataset after each epoch. This will allow the model to learn.\n",
    "# Validation_data will allow us to input in the test/validation datasets. This will allow us to see the model accuracy on the test/validation set.\n",
    "model_val.fit(x_train,y_train,epochs=50,shuffle=True,validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice that the printout now shows the validation accuracy as well? Is the validation accuracy higher or lower than the training accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You have successfully learnt how to create an artificial neural network model and trained it. Artficial neural networks are extremely powerful tools that can be used on very large datasets. For example, if you have a couple of hundred columns/features and over 100000 data points, it may be beneficial to use artificial neural networks instead of other machine learning techniques. Just remember, there are no strict rules on the number of nodes in the hidden layer or the number of hidden layers. Experiment with different neural networks to see which one provides the best result for your dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
